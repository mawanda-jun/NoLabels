\section{Introduction}
% \textcolor{red}{describe the problem you are working on, why it's important, and an overview of your results.}
Visual tasks, such as object classification and detection, have been successfully approached throught the supervised learning paradigm. However, since manually labelled data is costly and not scalable, unsupervised learning is gaining momentum.\newline
Recently a new unsupervised learning paradigm is raising: \emph{self-supervised} learning. The idea is to exploit different labellings that are freely available besides or within visual data, and to use them as intrinsic reward signals to learn general-purpose features.
For example, \cite{context_prediction} uses the relative spatial co-location of patches in images as a label. In \cite{unsupervised_models_recognition} they use object correspondence obtained through tracking in videos, and \cite{learning_by_moving} uses ego-motion information obtained by a mobile agent such as the Google car \cite{landmark_identification}. The features obtained with these approaches have been successfully transferred to classification and detections tasks with encouraging performances when compared to the supervised task.\newline
A fundamental difference between \cite{context_prediction} and \cite{unsupervised_models_recognition} is that the former method uses single images, while the latter use multiple images related through a temporal or viewpoint transformation. While it is true that biological agents typically make use of multiple images and other information, it is also true that single snapshot may carry more information than the one that has been extracted so far. In \cite{Noroozi_2016} Noorozi and Favaro worked on a nove supervised task the \emph{Jigsaw puzzle reassembly} problem, which builds features that yield high performance when transferred to detection and classification task. The experimental evaluations show them that the learned features capture semantically relevant content, and their method outperforms state of the art methods in several transfer learning benchmarks.\newline
In this report we would like to implement the method found in \cite{Noroozi_2016} and to apply the fine-tuning task to solve the classification task of of Food Images \cite{food_images} competition yielded by Kaggle \cite{kaggle}. 
\textcolor{red}{add what we found. It will be eventually empty since no results are already provided. Maybe we will explain that in the experiments section}

% What do we want to say?
% - Why supervised learning is so problematic;
% - Ways that are already been found that solve that problem;
% - Why we choose this kind of unspervised learning
% -- very promising
% -- simplicity of implementation: it deals only with images and uses AlexNet (simple architecture)
% - We found that... (what? Maybe a better implementation of the paper has produces the same results in very less time).

