import numpy as np
import h5py
import random
import tensorflow as tf
from config import conf
import os
from PIL import Image
# give fixed seed so we can push label and read them as integers. TODO: sistemare questo obbrobrio
random.seed(1)

AUTOTUNE = tf.data.experimental.AUTOTUNE


class H5Generator:
    """
    This is a generator of the file. We don't have to open it every time: we just open it once and then call it
    with exact parameters. In addition I've created a "prefetch" function, so the function takes care to pre-load the
    dataset and keep the training more smooth.
    """

    def __init__(self, file):
        """
        Open file once. The object CropsGenerator is kept alive for all the training (and evaluation). So the file will
        remain opened for the whole time.
        :param file:
        """
        self.h5f = h5py.File(file, 'r')  # it will be closed when the context will be terminated

    def __call__(self, mode, num_classes, *args, **kwargs):
        # dummy_y = 0
        for img in self.h5f[mode]:
            yield img, int(random.randrange(num_classes))


class CropsGenerator:
    """
    Read HD5F file, one batch at a time, and serve a jigsaw puzzle.
    """

    def __init__(self, conf, max_hamming_set):
        self.data_path = conf.data_path  # path to hd5f file
        self.img_generator = H5Generator(self.data_path)
        self.numChannels = conf.numChannels  # num of input image channels
        self.numCrops = conf.numCrops  # num of jigsaw crops
        self.original_dim = conf.original_dim  # size of the input image
        self.cropSize = conf.cropSize  # size of crop (255)
        self.cellSize = conf.cellSize  # size of each cell (75)
        self.tileSize = conf.tileSize  # size of tile in cell (64)
        self.colorJitter = conf.colorJitter  # number of pixels for color jittering
        self.batchSize = conf.batchSize  # training_batch_size
        self.val_batch_size = conf.val_batch_size
        self.conf = conf
        self.meanTensor, self.stdTensor = self.get_stats()
        # the <max_hamming_set> comes from file generated by <generate_hamming_set>. For further information see it.
        self.maxHammingSet = np.array(max_hamming_set, dtype=np.uint8)
        self.numClasses = conf.hammingSetSize  # number of different jigsaw classes

        # shapes of datasets (train, validation, test):
        # (70000, 256, 256, 3)
        # (25000, 256, 256, 3)
        # (5000, 256, 256, 3)
        # do not retrieve info about dataset with h5f['train_img'][:].shape since it loads the whole dataset into RAM
        # self.num_train_batch = self.img_generator.h5f['train_dim'].astype(np.int32)
        # self.num_val_batch = self.img_generator.h5f['val_dim'].astype(np.int32)
        # self.num_test_batch = self.img_generator.h5f['test_dim'].astype(np.int32)
        self.num_train_batch = conf.N_train_imgs // self.batchSize
        self.num_val_batch = conf.N_val_imgs // self.batchSize
        self.num_test_batch = conf.N_test_imgs // self.batchSize

    def get_stats(self):
        """
        Return mean and std from dataset. It has been memorized. If not mean or std have been saved a KeyError is raised.
        :return:
        """
        # with h5py.File(self.data_path, 'r') as h5f:
        mean = self.img_generator.h5f['train_mean'][:].astype(np.float32)
        std = self.img_generator.h5f['train_std'][:].astype(np.float32)
        if self.numChannels == 1:
            mean = np.expand_dims(mean, axis=-1)
            std = np.expand_dims(std, axis=-1)
        return mean, std

    def create_croppings(self, x: tf.Tensor, y=tf.Tensor):
        """
        Makes croppings from image
        The 3x3 grid is numbered as follows:
        0    1    2
        3    4    5
        6    7    8
        :param x = 3D numpy array
        :param perm_index = index of referred permutation in max_hamming_set
        :return array of croppings (<num_croppings>) made of (heigh x width x colour channels) arrays
        """

        y_dim, x_dim = x.shape[:2]
        perm_index = int(random.randrange(self.numClasses))

        # Have the x & y coordinate of the crop
        if x_dim != self.cropSize:
            # dimension of x is bigger than cropSize aka it has not been cropped before
            crop_x = random.randrange(x_dim - self.cropSize)
            crop_y = random.randrange(y_dim - self.cropSize)
        else:
            crop_x, crop_y = 0, 0

        croppings = []
        # for v in tf.gather(self.maxHammingSet, y):
        #     pass
        for hm_index in self.maxHammingSet[perm_index]:
            # It's sort of the contrary wrt previous behaviour. Now we find the hm_index crop we want to locate and
            # we create its cropping. Then we stack in order, so the hamming_set order is kept.
            # Define behaviour of col and rows to keep compatibility with previous code
            col = hm_index % 3
            row = int(hm_index/3)

            x_start = crop_x + col * self.cellSize + random.randrange(self.cellSize - self.tileSize)
            y_start = crop_y + row * self.cellSize + random.randrange(self.cellSize - self.tileSize)
            # Put the crop in the list of pieces randomly according to the number picked from max_hamming_set
            crop = x[y_start:y_start + self.tileSize, x_start:x_start + self.tileSize, :]
            crop = self.color_channel_jitter(crop)  # jitter every x in a random way
            croppings.append(crop)
        x = tf.stack(croppings, axis=-1)
        return x, y

    def normalize_image(self, x: tf.Tensor, y: tf.Tensor):
        """
        Normalize data one image at a time
        :param x: is a single images.
        :return:
        """
        # make it greyscale with probability 0.3% as in the paper
        if random.random() < 0.3:
            b = x[..., 0]
            g = x[..., 1]
            r = x[..., 2]
            x = 0.21 * r + 0.72 * g + 0.07 * b
            # expanding dimension to preserve net layout
            x = tf.expand_dims(x, axis=-1)
            x = tf.concat([x, x, x], axis=-1)

        # make the image distant from std deviation of the dataset
        x = tf.math.subtract(x, self.meanTensor)
        x = tf.math.divide(x, self.stdTensor)

        # tiles, y = self.create_croppings(x)

        return x, y

    def one_hot(self, x, y):
        """
        OneHot encoding for y label.
        :param y: label
        :return: y in the format of OneHot
        """
        return x, tf.one_hot(y, self.numClasses)

    def generate(self, mode='train'):
        normalize_func = lambda x, y: self.normalize_image(x, y)
        create_croppings_func = lambda x, y: self.create_croppings(x, y)
        onehot_func = lambda x, y: self.one_hot(x, y)

        if mode == 'val':
            batch_size = self.val_batch_size
        else:
            batch_size = self.batchSize

        h5f_label = mode + '_img'
        dataset = (tf.data.Dataset.from_generator(
            lambda: self.img_generator(h5f_label, self.numClasses),  # generator
            (tf.float32, tf.int32),  # input types
            (tf.TensorShape([self.original_dim, self.original_dim, self.numChannels]),  # shapes of input types
             tf.TensorShape(())))
                   .map(normalize_func, num_parallel_calls=AUTOTUNE)  # normalize input for mean and std
                   .map(create_croppings_func, num_parallel_calls=AUTOTUNE)  # create actual croppings
                   .map(onehot_func, num_parallel_calls=AUTOTUNE)  # convert label into one_hot encoding
                   .batch(batch_size)  # defined batch_size
                   .prefetch(AUTOTUNE)  # number of batches to be prefetch.
                   .repeat()  # repeats the dataset when it is finished
                   )
        return dataset

    def color_channel_jitter(self, img):
        """
        Spatial image jitter, aka movement of color channel in various manners
        """
        if self.colorJitter == 0:
            return img
        r_jit = random.randrange(-self.colorJitter, self.colorJitter)
        g_jit = random.randrange(-self.colorJitter, self.colorJitter)
        b_jit = random.randrange(-self.colorJitter, self.colorJitter)
        R = img[:, :, 0]
        G = img[:, :, 1]
        B = img[:, :, 2]
        return tf.stack((
            tf.roll(R, r_jit, axis=0),
            tf.roll(G, g_jit, axis=1),
            tf.roll(B, b_jit, axis=0)
        ), axis=2)


# UNCOMMENT ADDITION AND DIVISION PER MEAN AND STD BEFORE TRY TO SEE IMAGES

# if __name__ == '__main__':
#     os.chdir(os.pardir)
#     with h5py.File(os.path.join('Dataset', conf.resources, conf.hammingFileName + str(conf.hammingSetSize) + '.h5'), 'r') as h5f:
#         HammingSet = np.array(h5f['max_hamming_set'])
#
#     dataset = CropsGenerator(conf, HammingSet)
#     # generator = H5Generator(conf.data_path)
#     # for img in generator('train_img'):
#     #     Image.fromarray(img).show()
#     #     input()
#     mean = dataset.meanTensor
#     std = dataset.stdTensor
#     i=0
#     for img, label in dataset.yield_cropped_images():
#         image = img
#         lbl = label
#         # for i in range(img.shape[-1]):
#             # Image.fromarray(np.array(image[..., i], dtype=np.uint8)).show()
#             # print(i)
#         # Image.fromarray(np.array(image[:, :, :, ], dtype=np.uint8)).show()
#         if i < 7:
#             i+=1
#         else:
#             break
#     complete = np.zeros((192, 192, 3))
#     complete[0:64, 0:64] = image[:, :, :, dataset.maxHammingSet[lbl][0]]
#     complete[0:64, 64:128] = image[:, :, :, dataset.maxHammingSet[lbl][1]]
#     complete[0:64, 128:192] = image[:, :, :, dataset.maxHammingSet[lbl][2]]
#     complete[64:128, 0:64] = image[:, :, :, dataset.maxHammingSet[lbl][3]]
#     complete[64:128, 64:128] = image[:, :, :, dataset.maxHammingSet[lbl][4]]
#     complete[64:128, 128:192] = image[:, :, :, dataset.maxHammingSet[lbl][5]]
#     complete[128:192, 0:64] = image[:, :, :, dataset.maxHammingSet[lbl][6]]
#     complete[128:192, 64:128] = image[:, :, :, dataset.maxHammingSet[lbl][7]]
#     complete[128:192, 128:192] = image[:, :, :, dataset.maxHammingSet[lbl][8]]
#     print(dataset.maxHammingSet[lbl])
#     # img1 = (image[:, :, :, 1] + mean)*std
#     # img = image[:, :, :, 0]
#     # img += img.min()
#     # img *=
#     # complete += complete.min()
#     # complete *= (255.0/complete.max())
#     complete = np.array(complete, dtype=np.uint8)
#     img1 = Image.fromarray(complete)
#     img1.show()
